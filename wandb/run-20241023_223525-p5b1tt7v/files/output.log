/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/doductai/Desktop/AI and ML/MLOps/EmotionRecognition/models exists and is not empty.

  | Name       | Type               | Params | Mode
----------------------------------------------------------
0 | dropout    | Dropout            | 0      | train
1 | backbone   | Sequential         | 14.7 M | train
2 | classifier | Linear             | 3.6 K  | train
3 | acc        | MulticlassAccuracy | 0      | train
----------------------------------------------------------
14.7 M    Trainable params
0         Non-trainable params
14.7 M    Total params
58.902    Total estimated model params size (MB)
49        Modules in train mode
0         Modules in eval mode
Epoch 0: 100%|â–ˆ| 112/112 [00:29<00:00,  3.84it/s, v_num=tt7v, train/train_loss_step=1.830, train/train_acc_step=0.250, val/val_loss=2.980, val
/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.
/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.
                                                                                                                                              
Error executing job with overrides: []
Traceback (most recent call last):
  File "/Users/doductai/Desktop/AI and ML/MLOps/EmotionRecognition/train.py", line 49, in main
    trainer.fit(model,data)
  File "/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 206, in run
    self.on_advance_end()
  File "/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 386, in on_advance_end
    self.epoch_loop.update_lr_schedulers("epoch", update_plateau_schedulers=not self.restarting)
  File "/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 349, in update_lr_schedulers
    self._update_learning_rates(interval=interval, update_plateau_schedulers=update_plateau_schedulers)
  File "/Users/doductai/anaconda3/envs/GNN_M1/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 384, in _update_learning_rates
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: ReduceLROnPlateau conditioned on metric train_loss which is not available. Available metrics are: ['train/train_loss', 'train/train_loss_step', 'train/train_acc', 'train/train_acc_step', 'val/val_loss', 'val/val_acc', 'train/train_loss_epoch', 'train/train_acc_epoch']. Condition can be set using `monitor` key in lr scheduler dict

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
